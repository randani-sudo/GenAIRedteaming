# ML Service with GPU (CUDA) for training/inference on DGX or GPU hosts
# Build: docker build -f Dockerfile.gpu -t gold-rhinoceros-ml-gpu .
# Run: docker run --gpus all -p 8000:8000 -v ml_models:/app/models gold-rhinoceros-ml-gpu
FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 python3-pip curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

COPY . .
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
